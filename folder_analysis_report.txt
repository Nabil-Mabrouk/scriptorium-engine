--- Filesystem Structure ---
src/
    __pycache__/
    core/
    crew/
    project/
    __init__.py
    main.py
        __init__.cpython-312.pyc
        main.cpython-312.pyc
        __pycache__/
        __init__.py
        config.py
        database.py
        exceptions.py
        models.py
        schemas.py
        task_queue.py
            __init__.cpython-312.pyc
            config.cpython-312.pyc
            database.cpython-312.pyc
            dependencies.cpython-312.pyc
            task_queue.cpython-312.pyc
        __pycache__/
        __init__.py
        agents.py
        models.py
        pricing.py
        router.py
        schemas.py
        service.py
        tasks.py
        worker.py
            __init__.cpython-312.pyc
            agents.cpython-312.pyc
            models.cpython-312.pyc
            pricing.cpython-312.pyc
            router.cpython-312.pyc
            schemas.cpython-312.pyc
            service.cpython-312.pyc
            tasks.cpython-312.pyc
            worker.cpython-312.pyc
        __pycache__/
        __init__.py
        chapter_router.py
        dependencies.py
        exceptions.py
        models.py
        part_router.py
        router.py
        schemas.py
        service.py
            __init__.cpython-312.pyc
            chapter_router.cpython-312.pyc
            dependencies.cpython-312.pyc
            models.cpython-312.pyc
            part_router.cpython-312.pyc
            router.cpython-312.pyc
            schemas.cpython-312.pyc
            service.cpython-312.pyc

--- Python File Contents (.py files) ---

--- FILE: C:\Projects\57-scriptorium-engine\src\main.py ---
# src/main.py
from fastapi import FastAPI
from src.core.config import settings
from src.core.database import Base, engine
from src.core.task_queue import task_queue
from src.project.chapter_router import router as chapter_router
from src.project.router import router as project_router
from src.project.part_router import router as part_router
from src.crew.router import router as crew_router

# NEW IMPORTS for Rate Limiter
from fastapi_limiter import FastAPILimiter
from redis.asyncio import Redis # Use async Redis client

# NEW: Import CORSMiddleware
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI(title="Scriptorium-Engine", version=settings.APP_VERSION)

# NEW: CORS Configuration
origins = [
    "http://localhost:5173",  # This is the default port for Vite dev server
    # Add any other origins where your frontend might be hosted in development or production
    # e.g., "https://your.production.domain"
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"], # Allows all HTTP methods (GET, POST, PUT, DELETE, etc.)
    allow_headers=["*"], # Allows all headers
)

@app.on_event("startup")
async def startup_event():
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)
    task_queue.configure(settings.REDIS_URL)
    await task_queue.connect()

    # NEW: Initialize FastAPILimiter with Redis
    redis_client = Redis.from_url(settings.REDIS_URL, encoding="utf-8", decode_responses=True)
    await FastAPILimiter.init(redis_client)
    print("⚡ FastAPILimiter initialized.")

@app.on_event("shutdown")
async def shutdown_event():
    await task_queue.close()
    # NEW: Close FastAPILimiter connections
    await FastAPILimiter.close()
    print("🔌 FastAPILimiter closed.")

app.include_router(project_router)
app.include_router(chapter_router)
# NEW: Include the new part_router
app.include_router(part_router)
app.include_router(crew_router)

@app.get("/", tags=["Health Check"])
async def health_check():
    return {"status": "ok", "version": settings.APP_VERSION}

--- FILE: C:\Projects\57-scriptorium-engine\src\__init__.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\core\config.py ---
# src/core/config.py
from pydantic_settings import BaseSettings, SettingsConfigDict
from decimal import Decimal # Import Decimal
from typing import Dict # Import Dict

class Settings(BaseSettings):
    model_config = SettingsConfigDict(env_file=".env", env_file_encoding="utf-8")

    # --- Core Application Settings ---
    DATABASE_URL: str
    REDIS_URL: str = "redis://localhost:6379"
    APP_VERSION: str = "0.1.0"
    ENVIRONMENT: str = "development"

    # --- LLM Settings ---
    OPENAI_API_KEY: str
    # This will be the DEFAULT model if not specified per agent
    DEFAULT_OPENAI_MODEL_NAME: str #= "gpt-4o-mini" # Renamed from OPENAI_MODEL_NAME

    # NEW: LLM Pricing Configuration
    # This can be loaded from an environment variable as a JSON string,
    # or defined directly with defaults, or loaded from a separate JSON/YAML file.
    # For simplicity, we'll make it a JSON string loaded from env.
    # Example JSON: {"gpt-4o-mini": {"prompt": 0.15, "completion": 0.60}, "gpt-4-turbo": {"prompt": 10.00, "completion": 30.00}}
    LLM_PRICING: Dict[str, Dict[str, Decimal]] = {
        "gpt-4o-mini": {"prompt": Decimal("0.15"), "completion": Decimal("0.60")},
        "gpt-4-turbo": {"prompt": Decimal("10.00"), "completion": Decimal("30.00")},
        "gpt-4": {"prompt": Decimal("30.00"), "completion": Decimal("60.00")},
        "gpt-3.5-turbo-0125": {"prompt": Decimal("0.50"), "completion": Decimal("1.50")},
    }

settings = Settings()

# NOTE: If loading LLM_PRICING from an environment variable (e.g., LLM_PRICING_JSON),
# you'd need a Pydantic validator to parse the JSON string into the Dict[str, Dict[str, Decimal]] format.
# For now, defining it directly with defaults is simplest for demonstration,
# but for production, externalizing this to a file or a complex ENV var is common.

--- FILE: C:\Projects\57-scriptorium-engine\src\core\database.py ---
from sqlalchemy import MetaData
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker, declarative_base

from src.core.config import settings


# Naming convention for database constraints (indexes, keys, etc.)
# This ensures consistency across the database schema.
POSTGRES_INDEXES_NAMING_CONVENTION = {
    "ix": "%(column_0_label)s_idx",
    "uq": "%(table_name)s_%(column_0_name)s_key",
    "ck": "%(table_name)s_%(constraint_name)s_check",
    "fk": "%(table_name)s_%(column_0_name)s_fkey",
    "pk": "%(table_name)s_pkey",
}

# Create a metadata object with the defined naming convention
metadata = MetaData(naming_convention=POSTGRES_INDEXES_NAMING_CONVENTION)

# Define the base class for declarative models
# All our DB models will inherit from this class.
Base = declarative_base(metadata=metadata)

# Create the async engine for connecting to the database
# `echo=True` is useful for debugging as it logs all SQL statements.
engine = create_async_engine(settings.DATABASE_URL, echo=False)

# Create a configured "Session" class
# This is a factory for creating new session objects.
AsyncSessionFactory = sessionmaker(
    bind=engine,
    class_=AsyncSession,
    expire_on_commit=False,  # Important for async usage
)

# Dependency to get a DB session. This will be used in API routes.
async def get_db_session() -> AsyncSession:
    """
    Dependency function that yields a new SQLAlchemy async session.
    """
    async with AsyncSessionFactory() as session:
        yield session


--- FILE: C:\Projects\57-scriptorium-engine\src\core\exceptions.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\core\models.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\core\schemas.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\core\task_queue.py ---
# src/core/task_queue.py
from arq import create_pool
from arq.connections import ArqRedis, RedisSettings

class TaskQueue:
    pool: ArqRedis = None
    # This will hold the correctly configured RedisSettings object
    redis_settings: RedisSettings = None

    @classmethod
    def configure(cls, redis_settings_url: str):
        """Configures the Redis settings from a URL. Does not connect."""
        # Use the correct 'from_dsn' method and store the object
        cls.redis_settings = RedisSettings.from_dsn(redis_settings_url)

    @classmethod
    async def connect(cls):
        """Initializes the connection pool to Redis."""
        if not cls.redis_settings:
            raise ConnectionError("TaskQueue is not configured. Call .configure() first.")
        cls.pool = await create_pool(cls.redis_settings)

    @classmethod
    async def close(cls):
        """Closes the connection pool."""
        if cls.pool:
            await cls.pool.close()

    @classmethod
    async def enqueue(cls, function_name: str, *args, **kwargs):
        """Enqueues a job to be run by a worker."""
        if not cls.pool:
            raise ConnectionError("TaskQueue is not connected. Call .connect() first.")
        return await cls.pool.enqueue_job(function_name, *args, **kwargs)

# A single instance to be used throughout the application
task_queue = TaskQueue()

--- FILE: C:\Projects\57-scriptorium-engine\src\core\__init__.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\crew\agents.py ---

from agents import Agent # This is the crucial new import
from pydantic import BaseModel, Field # Keep pydantic for output types
from src.core.config import settings
from .schemas import PartListOutline  # Add this import



# --- AGENT ROSTER (Single Source of Truth) ---
AGENT_ROSTER = {
    "Historian AI": "A master storyteller and historian of technology, ideal for chapters requiring historical analogies and context.",
    "Technologist AI": "An expert at explaining complex technical concepts in a simple, intuitive way. Best for chapters explaining core technologies like multi-agent systems.",
    "Philosopher AI": "An expert in exploring the profound 'so what?' questions and ethical implications. Best for speculative or philosophical chapters.",
    "Theorist AI": "The primary voice of the book's core argument. Excellent for introductory, concluding, and synthesis chapters that weave the central thesis throughout.",
    "Continuity Editor AI": "A meticulous editor focused on ensuring smooth transitions and logical flow between chapters."
}

class StringOutput(BaseModel):
    text: str = Field(..., description="The generated text content.")


# ORIGINAL: def create_architect_chain(): ...
# NEW:
architect_part_agent = Agent(
    name="BookArchitectAgent",
    instructions=(
        "You are a master strategic thinker, specialist in structuring book outlines.\n"
        "Your goal is to transform raw text ideas into comprehensive, structured book outlines.\n\n"
        "### Backstory:\n"
        "You are a master strategic thinker, skilled at transforming free-form ideas into structured, actionable plans.\n"
        "You excel at identifying core themes, creating logical hierarchies, and building detailed briefs.\n\n"
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=PartListOutline,
    # No tools for this agent as per your example, or use WebSearchTool() if applicable
)

# ORIGINAL: def create_continuity_editor_chain(): ...
# NEW:
continuity_editor_agent = Agent(
    name="ContinuityEditorAgent",
    instructions=(
        "You are a Continuity Editor AI focused on ensuring smooth transitions between chapters.\n"
        "### Backstory:\n"
        "You are a seasoned book editor with a keen eye for narrative structure and pacing. "
        "Your specialty is ensuring a seamless reading experience. You don't rewrite content; "
        "you identify jarring transitions, suggest bridging sentences, and point out thematic "
        "disconnects, providing clear, concise, and constructive feedback.\n\n"
        "### Chapter Transition Analysis:\n"
        "Analyze the transition and provide actionable feedback to improve narrative flow."
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=StringOutput, # Expecting raw text feedback
)


# src/crew/agents.py
# ... (existing imports) ...
from src.crew.schemas import PartListOutline, ChapterListOutline # Ensure ChapterListOutline is imported

# ... (existing architect_part_agent definition) ...

# NEW: Architect Agent for Chapter Detailing
architect_chapter_agent = Agent(
    name="ChapterArchitectAgent",
    instructions=(
        "You are a master strategic thinker, specializing in structuring detailed chapter outlines for a book part.\n"
        "Your goal is to generate a list of chapters for a given book part, along with detailed briefs for each chapter.\n\n"

    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME,
    output_type=ChapterListOutline, # <--- This is crucial!
)

# src/crew/agents.py
# ... (existing imports) ...
from src.crew.schemas import PartListOutline, ChapterListOutline # Ensure ChapterListOutline is imported

# ... (existing architect_part_agent definition) ...

# NEW: Architect Agent for Chapter Detailing
architect_chapter_agent = Agent(
    name="ChapterArchitectAgent",
    instructions=(
        "You are a master strategic thinker, specializing in structuring detailed chapter outlines for a book part.\n"
        "Your goal is to generate a list of chapters for a given book part, along with detailed briefs for each chapter.\n\n"
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME,
    output_type=ChapterListOutline, # <--- This is crucial!
)


# ORIGINAL: def create_technologist_chain(): ...
# NEW:
technologist_agent = Agent(
    name="TechnologistAIAgent",
    instructions=(
        "You are a Technologist AI explaining complex technical concepts.\n"
        "### Backstory:\n"
        "You are a brilliant technologist and educator. You excel at breaking down complex, "
        "technical concepts into simple, intuitive explanations using powerful, clear analogies.\n\n"
        "### Chapter Assignment:"
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=StringOutput,
)

# ORIGINAL: def create_philosopher_chain(): ...
# NEW:
philosopher_agent = Agent(
    name="PhilosopherAIAgent",
    instructions=(
        "You are a Philosopher AI exploring deeper implications.\n"
        "### Backstory:\n"
        "You are a philosopher of technology and a futurist. You don't just explain what something is; "
        "you explore what it *means*. Your role is to ask the profound 'so what?' questions, exploring the ethical, "
        "societal, and existential implications of ideas.\n\n"
        "### Chapter Assignment:"
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=StringOutput,
)

# ORIGINAL: def create_theorist_chain(): ...
# NEW:
theorist_agent = Agent(
    name="TheoristAIAgent",
    instructions=(
        "You are a master synthesizer, weaving together disparate ideas from history, technology, and philosophy into a single, powerful, and cohesive "
        "narrative. You ensure the central thesis is the golden thread running through every chapter you touch.\n\n"
        "### Assignment:"
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=StringOutput,
)

# ORIGINAL: def create_historian_chain(): ...
# NEW:
historian_agent = Agent(
    name="HistorianAIAgent",
    instructions=(
        "You are a Historian AI writing a book chapter using historical analogies.\n"
        "### Backstory:\n"
        "You are a master storyteller and a historian of technology and science. You have an "
        "uncanny ability to find the perfect analogy from the past to illuminate a complex "
        "modern idea. Your writing is engaging, rich with detail, and always serves to "
        "clarify the core argument by showing how history repeats itself.\n\n"
        "### Chapter Assignment:" # Inputs will be prepended by Runner.run
    ),
    model=settings.DEFAULT_OPENAI_MODEL_NAME, # Use the default from settings
    output_type=StringOutput, # Expecting raw text chapter content
)
# --- Agent Instances Map ---
# Update AGENT_INSTANCES to include the new agent
AGENT_INSTANCES = {
    "Architect Part AI": architect_part_agent,
    "Architect Chapter AI": architect_chapter_agent, # NEW ADDITION
    "Continuity Editor AI": continuity_editor_agent,
    "Historian AI": historian_agent,
    "Technologist AI": technologist_agent,
    "Philosopher AI": philosopher_agent,
    "Theorist AI": theorist_agent,
}


--- FILE: C:\Projects\57-scriptorium-engine\src\crew\models.py ---
import uuid
from datetime import datetime
from sqlalchemy import Column, String, Integer, Numeric, DateTime, ForeignKey, UUID
from src.core.database import Base


class CrewRunLog(Base):
    __tablename__ = "crew_run_logs" # New table name

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id", ondelete="CASCADE"), nullable=False)
    # A descriptive name for the overall job that was run.
    initiating_task_name = Column(String, nullable=False)
    model_name = Column(String, nullable=False)
    prompt_tokens = Column(Integer, nullable=False)
    completion_tokens = Column(Integer, nullable=False)
    total_tokens = Column(Integer, nullable=False)
    total_cost = Column(Numeric(10, 8), nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\pricing.py ---
# src/crew/pricing.py
from decimal import Decimal
from src.core.config import settings # Import the settings object

# REMOVE THE ENTIRE MODEL_PRICING DICTIONARY BLOCK

def calculate_cost(model_name: str, prompt_tokens: int, completion_tokens: int) -> Decimal:
    """Calculates the cost of an LLM call based on token usage."""
    # Get pricing from the global settings object
    pricing = settings.LLM_PRICING.get(model_name)
    if not pricing:
        # Fallback for unknown models to avoid errors
        print(f"⚠️ Warning: Pricing not found for model '{model_name}'. Cost will be 0.0.")
        return Decimal("0.0")

    # Your previously discussed fix for negative tokens:
    if prompt_tokens < 0 or completion_tokens < 0:
        # This should ideally be caught upstream or indicate an issue with LLM usage reporting.
        print(f"⚠️ Warning: Negative token counts received for model '{model_name}'. Prompt: {prompt_tokens}, Completion: {completion_tokens}. Setting cost to 0.0.")
        return Decimal("0.0") # Return 0.0 for invalid inputs

    prompt_cost = (Decimal(prompt_tokens) / Decimal(1_000_000)) * pricing["prompt"]
    completion_cost = (Decimal(completion_tokens) / Decimal(1_000_000)) * pricing["completion"]

    return prompt_cost + completion_cost

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\router.py ---
# src/crew/router.py
import uuid
from fastapi import APIRouter, Depends, status, Body

from src.core.task_queue import task_queue
from src.project.dependencies import valid_project_id, valid_part_id
from src.project.schemas import ProjectRead, PartRead
from src.crew.schemas import TaskStatus, FinalizationRequest

# NEW: Import RateLimiter
from fastapi_limiter.depends import RateLimiter

router = APIRouter(prefix="/crew", tags=["Crew AI"])

# --- Phase 1 Endpoint ---
@router.post(
    "/generate-parts/{project_id}",
    status_code=status.HTTP_202_ACCEPTED,
    response_model=TaskStatus,
    summary="Generate High-Level Part Structure",
    dependencies=[Depends(RateLimiter(times=5, seconds=60))] # NEW: 5 requests per minute
)
async def queue_part_generation(
    project: ProjectRead = Depends(valid_project_id),
):
    """
    Queues a background job for the Architect AI to generate a high-level
    list of Parts and their summaries from the project's raw blueprint.
    """
    job = await task_queue.enqueue("part_generation_worker", project.id)
    return TaskStatus(job_id=job.job_id, status="queued")

# --- NEW: Phase 2 Endpoint ---
@router.post(
    "/generate-chapters/{part_id}",
    status_code=status.HTTP_202_ACCEPTED,
    response_model=TaskStatus,
    summary="Generate Detailed Chapter Outline for a Part",
    dependencies=[Depends(RateLimiter(times=10, seconds=60))] # NEW: 10 requests per minute
)
async def queue_chapter_detailing(
    part: PartRead = Depends(valid_part_id),
):
    """
    Queues a background job to generate a detailed chapter outline for a
    specific part of the book.
    """
    job = await task_queue.enqueue("chapter_detailing_worker", part.id)
    return TaskStatus(job_id=job.job_id, status="queued")

# NEW: Phase 5 Endpoint
@router.post(
    "/projects/{project_id}/finalize", # Note: This path is inconsistent with prefix, but let's follow existing.
    status_code=status.HTTP_202_ACCEPTED,
    response_model=TaskStatus,
    summary="Generate Introduction or Conclusion",
    dependencies=[Depends(RateLimiter(times=2, seconds=300))] # NEW: 2 requests per 5 minutes (finalization is heavy)
)
async def queue_finalization(
    project: ProjectRead = Depends(valid_project_id),
    request: FinalizationRequest = Body(...)
):
    """
    Queues a background job for the Theorist AI to write the book's
    introduction or conclusion based on the full content.
    """
    job = await task_queue.enqueue(
        "finalization_worker",
        project.id,
        request.task_type
    )
    return TaskStatus(job_id=job.job_id, status="queued")

# backend router
@router.get("/crew/status/{job_id}")
async def job_status(job_id: str):
    job = await task_queue.pool.get_job(job_id)
    return {"status": job.status if job else "error"}

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\schemas.py ---
from pydantic import BaseModel, Field
from typing import List
from pydantic import BaseModel, Field, field_validator
from typing import List, Union
import json
from pydantic import BaseModel, Field, validator, ValidationError
from typing import List, Union

class TaskStatus(BaseModel):
    """A simple schema for returning the status of a queued job."""
    job_id: str
    status: str

# --- Brief and Chapter Schemas (No changes here) ---
class ChapterBrief(BaseModel):
    """A structured writing brief for a specialist agent."""
    thesis_statement: str = Field(..., description="The central thesis or main argument the chapter must defend.")
    narrative_arc: str = Field(..., description="A description of the chapter's narrative structure.")
    required_inclusions: List[str] = Field(..., description="A list of non-negotiable concepts that MUST be included.")
    key_questions_to_answer: List[str] = Field(..., description="The specific questions the chapter must answer.")

class ChapterOutline(BaseModel):
    """Defines the structure for a single chapter."""
    chapter_number: int
    title: str
    brief: ChapterBrief
    suggested_agent: str

# --- NEW: Schemas for the "Divide and Conquer" Workflow ---

class PartOnlyOutline(BaseModel):
    part_number: int = Field(..., description="Numerical order of the part")
    title: str = Field(..., description="Title of the part")
    summary: str = Field(..., description="Brief summary of the part's content")

    @validator('part_number')
    def part_number_positive(cls, v):
        if v < 1:
            raise ValueError('Part number must be positive integer')
        return v

class PartListOutline(BaseModel):
    parts: List[PartOnlyOutline] = Field(..., description="List of book parts")
    
    @validator('parts', pre=True)
    def ensure_list(cls, v):
        """Handle different output formats for Pydantic V1"""
        if isinstance(v, dict):
            # Convert dict to list of parts
            if 'parts' in v:
                return v['parts']
            # Handle parts as dictionary values
            return list(v.values())
        elif isinstance(v, str):
            # Try to parse JSON string
            try:
                data = json.loads(v)
                if 'parts' in data:
                    return data['parts']
                return data
            except json.JSONDecodeError:
                pass
        return v
    
    @validator('parts')
    def check_min_parts(cls, v):
        """Ensure at least 3 parts are generated"""
        if len(v) < 3:
            raise ValueError('At least 3 parts are required')
        return v

class ChapterListOutline(BaseModel):
    """A Pydantic model for a list of chapters for a single part."""
    chapters: List[ChapterOutline]


# --- Original Schemas for Final Assembly ---

class PartOutline(BaseModel):
    """Defines a part of the book, which contains multiple chapters."""
    part_number: int
    title: str
    summary: str
    chapters: List[ChapterOutline]

class BookOutline(BaseModel):
    """The complete, final, and structured outline for the entire book."""
    parts: List[PartOutline]

# NEW: Schema for the finalization request body
class FinalizationRequest(BaseModel):
    task_type: str = Field(..., description="The type of finalization task to run, e.g., 'introduction' or 'conclusion'.")

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\service.py ---
# src/crew/service.py
import asyncio
import uuid
from typing import Any, Dict
from decimal import Decimal # Needed for log_crew_run's local calculations

# NEW IMPORT: Circuit Breaker
#from circuitbreaker import CircuitBreaker, CircuitBreakerError

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select # Use future select for cleaner syntax
from sqlalchemy import update # Use update for project total_cost update
from sqlalchemy.orm import selectinload # For get_part_by_id, get_chapter_by_id

# NEW IMPORTS for openai-agents
from agents import Runner, RunResult # Make sure 'agents' is correctly importable

# Make sure these are the new Agent instances you defined in agents.py
# If you defined architect_chapter_agent, you'd import it here too.
from .agents import (
    AGENT_INSTANCES,
    architect_part_agent,
    architect_chapter_agent, # NEW IMPORT
    continuity_editor_agent,
    historian_agent,
    technologist_agent,
    philosopher_agent,
    theorist_agent,
    StringOutput
)

from src.core.config import settings
from src.project.models import Project, Part, Chapter
from src.project.service import (
    get_chapter_by_id, get_project_by_id, get_part_by_id,
    get_project_with_details, update_chapter_content
)
# REMOVE: from pydantic import BaseModel, Field, validator, ValidationError
from .schemas import PartListOutline, ChapterListOutline # Ensure all required schemas are here

# REMOVE all imports related to tasks.py, e.g.:
# from .tasks import (
#     prepare_part_generation_inputs,
#     prepare_chapter_detailing_inputs,
#     prepare_chapter_writing_inputs,
#     prepare_finalization_inputs,
#     prepare_transition_analysis_inputs
# )
from .models import CrewRunLog
from .pricing import calculate_cost

async def log_crew_run(
    session: AsyncSession,
    project_id: uuid.UUID,
    initiating_task_name: str,
    # This usage_metrics parameter will now always be the raw RunResult object
    # from the calling function (e.g., `run_result`).
    usage_metrics: Any,
):
    """Logs the metrics of a completed LLM run."""
    # Ensure we have a valid RunResult object and it has raw_responses
    if not usage_metrics or not hasattr(usage_metrics, 'raw_responses') or not usage_metrics.raw_responses:
        print(f"⚠️ Could not log run for '{initiating_task_name}': Invalid RunResult or no raw_responses found.")
        return

    # Extract the specific response (assuming the first one for simplicity for now)
    # and get its usage attribute.
    response_usage = getattr(usage_metrics.raw_responses[0], 'usage', None)

    if not response_usage:
        print(f"⚠️ Could not log run for '{initiating_task_name}': No usage data found in raw_response.")
        return

    prompt_tokens = 0
    completion_tokens = 0

    # Now extract from the 'response_usage' object which is of type 'Usage'
    if hasattr(response_usage, 'input_tokens'):
        prompt_tokens = response_usage.input_tokens
    if hasattr(response_usage, 'output_tokens'):
        completion_tokens = response_usage.output_tokens

    # Fallback for older OpenAI API keys if necessary, but input/output_tokens are common in new APIs
    # (This part might be less necessary if openai-agents consistently uses input/output_tokens)
    elif isinstance(response_usage, dict): # In case it's a dict for some reason
        prompt_tokens = response_usage.get('input_tokens', 0)
        completion_tokens = response_usage.get('output_tokens', 0)
        if prompt_tokens == 0 and completion_tokens == 0:
             prompt_tokens = response_usage.get('prompt_tokens', 0)
             completion_tokens = response_usage.get('completion_tokens', 0)


    total_tokens = prompt_tokens + completion_tokens

    # Corrected: Use settings.DEFAULT_OPENAI_MODEL_NAME for the model used in this cost calculation
    run_cost = calculate_cost(
        model_name=settings.DEFAULT_OPENAI_MODEL_NAME,
        prompt_tokens=prompt_tokens,
        completion_tokens=completion_tokens,
    )

    new_log = CrewRunLog(
        project_id=project_id, initiating_task_name=initiating_task_name,
        model_name=settings.DEFAULT_OPENAI_MODEL_NAME, prompt_tokens=prompt_tokens,
        completion_tokens=completion_tokens, total_tokens=total_tokens,
        total_cost=run_cost
    )
    session.add(new_log)

    # Update project total cost
    await session.execute(
        update(Project)
        .where(Project.id == project_id)
        .values(total_cost=Project.total_cost + run_cost)
    )

    await session.commit()
    print(f"📊 Run Logged: '{initiating_task_name}' - Tokens: {total_tokens}, Cost: ${run_cost:.6f}")

async def run_part_generation_crew(session: AsyncSession, project_id: uuid.UUID) -> bool:
    print(f"🚀 Starting Part generation for project: {project_id}")
    project = None # Initialize project outside try to ensure it's defined for except block if needed
    try:
        project = await get_project_by_id(session, project_id=project_id)
        if not project:
            print(f"❌ Part generation failed: Project {project_id} not found.")
            return False
        if not project.raw_blueprint:
            print(f"❌ Part generation failed: Project {project_id} has no raw blueprint defined.")
            return False

        # Direct input for the agent is the raw blueprint string
        agent_input = project.raw_blueprint

        print(f"🤖 Architect AI preparing part outline for project {project_id}...")

        # Execute the agent, expecting PartListOutline as output
        # `final_output_as` performs the Pydantic validation defined in architect_part_agent's output_type
        run_result: RunResult = await Runner.run(architect_part_agent, agent_input)
        part_list_outline: PartListOutline = run_result.final_output_as(PartListOutline)

        # The schema (PartListOutline) has a validator for `len(parts) < 3`.
        # If the output doesn't meet this, `final_output_as` would already have failed.
        # So, the check here becomes primarily for empty list if final_output_as somehow returns it,
        # or for additional business logic not covered by the schema.
        if not part_list_outline.parts: # Check if the list of parts is empty
            print(f"⚠️ Part generation failed: Agent returned an empty 'parts' list despite schema. Retrying or manual intervention may be needed.")
            return False

        # The schema validator for PartListOutline should ensure at least 3 parts.
        # This check confirms that the validation was respected and provides a clear message.
        if len(part_list_outline.parts) < 3:
            print(f"⚠️ Part generation failed: Agent generated only {len(part_list_outline.parts)} parts, expected at least 3 as per schema. Review agent instructions or model.")
            # Depending on strictness, you might return False here if this is a hard requirement
            # even if the Pydantic model didn't catch it (which it should have).
            # For now, it's a strong warning.
            pass # Continue if you want to proceed with fewer than 3, or return False

        # Print success details
        print(f"🔍 Generated {len(part_list_outline.parts)} parts:")
        for i, part_data in enumerate(part_list_outline.parts[:3]):  # Print first 3 parts
            print(f"  Part {part_data.part_number}: {part_data.title}")
            print(f"  Summary: {part_data.summary[:100]}...")
            if i == 2 and len(part_list_outline.parts) > 3:
                print(f"  ... and {len(part_list_outline.parts)-3} more parts")

        # Convert to dictionary and save to project
        # This now correctly dumps the entire PartListOutline object
        project.structured_outline = part_list_outline.model_dump()
        project.status = "PARTS_PENDING_VALIDATION"
        await session.commit()
        print(f"✅ Part structure generated for project {project_id}. Status: {project.status}")

        # NEW Check for usage data within raw_responses
        if hasattr(run_result, 'raw_responses') and run_result.raw_responses and hasattr(run_result.raw_responses[0], 'usage'):
            await log_crew_run(
                session=session,
                project_id=project.id,
                initiating_task_name="Phase 1: Part Generation",
                usage_metrics=run_result # Pass the entire RunResult object
            )
        else:
            print(f"⚠️ No usage metrics available in raw_responses for Part Generation run for project {project_id}.")

        return True

    except Exception as e:
        # Catch any exceptions during agent execution or Pydantic parsing
        project_status_message = ""
        if project:
            # Update project status to reflect failure
            project.status = "PART_GENERATION_FAILED"
            try: # Commit is crucial here
                await session.commit()
                project_status_message = f" for project {project.id}. Status set to {project.status}."
            except Exception as commit_e:
                print(f"❌ Failed to commit status update for project {project.id}: {commit_e}")
                project_status_message = f" for project {project.id} (status update failed)."

        print(f"🔥 Critical error during Part generation{project_status_message}: {str(e)}")
        import traceback
        traceback.print_exc() # Print full traceback for debugging
        return False


async def run_chapter_detailing_crew(session: AsyncSession, part_id: uuid.UUID) -> bool:
    print(f"🚀 Starting chapter detailing for part: {part_id}")
    part = None # Initialize part for potential error handling later
    try:
        part = await get_part_by_id(session, part_id=part_id)
        if not part:
            print(f"❌ Chapter detailing failed: Part {part_id} not found.")
            return False
        
        if not part.title or not part.summary:
            print(f"❌ Chapter detailing failed: Part {part_id} is missing title or summary. Cannot detail chapters.")
            return False

        # Prepare a single string input for the agent
        # We'll re-use architect_part_agent, ensure its instructions in agents.py
        # are broad enough, or create a specific architect_chapter_agent.
        agent_input = (
            f"Generate a detailed chapter outline for a book part. "
            f"The part title is '{part.title}' and its summary is '{part.summary}'.\n\n"
            "Provide a list of chapters, each chapter must have:\n"
            "- chapter_number: Positive integer, sequential.\n"
            "- title: A descriptive chapter title.\n"
            "- brief: A structured brief containing:\n"
            "  - thesis_statement: The central argument (string).\n"
            "  - narrative_arc: The chapter's structure (string).\n"
            "  - required_inclusions: List of key concepts to include (list of strings).\n"
            "  - key_questions_to_answer: List of questions the chapter must answer (list of strings).\n"
            "- suggested_agent: The name of the specialist AI agent best suited to write this chapter (e.g., 'Historian AI', 'Technologist AI', 'Philosopher AI', 'Theorist AI'). "
            "Choose from: 'Historian AI', 'Technologist AI', 'Philosopher AI', 'Theorist AI'."
            "\n\nOutput ONLY JSON matching the ChapterListOutline schema. Ensure at least 3 chapters are generated."
        )

        print(f"🤖 Architect AI preparing chapter outline for part {part.part_number} - '{part.title}'...")

        # Execute the agent, expecting ChapterListOutline as output
        run_result: RunResult = await Runner.run(architect_chapter_agent, agent_input) # <--- CRITICAL CHANGE HERE
        
        # Extract the structured output. If output doesn't conform to schema, error will be caught.
        chapter_list_outline: ChapterListOutline = run_result.final_output_as(ChapterListOutline)

        if not chapter_list_outline.chapters:
            print(f"⚠️ Chapter detailing failed: Agent returned an empty 'chapters' list.")
            return False
        
        # This check is less strict than PartListOutline, but good to have a minimum
        if len(chapter_list_outline.chapters) < 3:
             print(f"⚠️ Chapter detailing warning: Agent generated only {len(chapter_list_outline.chapters)} chapters for part {part.id}. Consider reviewing agent output or instructions.")

        project = part.project # Get the related project from the part

        # Update the project's structured_outline with the new chapter data for this part
        if project.structured_outline is None:
            project.structured_outline = {}
        
        # This needs to update the existing part entry in the structured_outline
        # or add it if it somehow wasn't there (though it should be after part generation)
        project.structured_outline[str(part.id)] = chapter_list_outline.model_dump()
        
        part.status = "CHAPTERS_PENDING_VALIDATION"
        
        session.add(project) # Ensure project is marked for update
        session.add(part)    # Ensure part is marked for update
        await session.commit()
        
        print(f"✅ Chapter structure generated for part {part.id}. Status: {part.status}")

        # NEW Check for usage data within raw_responses
        if hasattr(run_result, 'raw_responses') and run_result.raw_responses and hasattr(run_result.raw_responses[0], 'usage'):
            await log_crew_run(
                session=session,
                project_id=project.id,
                initiating_task_name="Phase 2: Chapter Detailing for Part {part.part_number}",
                usage_metrics=run_result # Pass the entire RunResult object
            )
        else:
            print(f"⚠️ No usage metrics available for Chapter Detailing run for part {part_id}.")

        return True

    except Exception as e:
        part_status_message = ""
        if part:
            part.status = "CHAPTER_DETAILING_FAILED"
            try:
                await session.commit()
                part_status_message = f" for part {part.id}. Status set to {part.status}."
            except Exception as commit_e:
                print(f"❌ Failed to commit status update for part {part.id}: {commit_e}")
                part_status_message = f" for part {part.id} (status update failed)."
        
        print(f"🔥 Critical error during Chapter detailing{part_status_message}: {str(e)}")
        import traceback
        traceback.print_exc()
        return False # Indicate failure


async def run_chapter_generation_crew(session: AsyncSession, chapter_id: uuid.UUID) -> bool:
    print(f"🚀 Starting content generation for chapter: {chapter_id}")
    chapter = None # Initialize chapter for error handling
    project_id = None # Initialize project_id for logging in case chapter not found
    try:
        chapter = await get_chapter_by_id(session, chapter_id=chapter_id)
        if not chapter or not chapter.part or not chapter.part.project:
            print(f"❌ Chapter content generation failed: Chapter {chapter_id} not found or is missing relationships.")
            return False

        project_id = chapter.part.project.id # Get project_id for logging
        
        # Retrieve the specific agent instance based on suggested_agent
        agent_instance = AGENT_INSTANCES.get(chapter.suggested_agent)
        if not agent_instance:
            print(f"❌ Chapter content generation failed: Agent instance not found for '{chapter.suggested_agent}'.")
            chapter.status = "AGENT_NOT_FOUND" # Update status to reflect issue
            await session.commit()
            return False

        if not chapter.title or not chapter.brief:
            print(f"❌ Chapter content generation failed: Chapter {chapter_id} is missing title or brief.")
            chapter.status = "BRIEF_MISSING"
            await session.commit()
            return False

        # Prepare a single string input for the agent based on the chapter brief
        # Reconstruct the brief into a readable string for the LLM
        brief_data = chapter.brief
        agent_input = (
            f"Chapter Title: {chapter.title}\n\n"
            f"Brief:\n"
            f"- Thesis Statement: {brief_data.get('thesis_statement', 'N/A')}\n"
            f"- Narrative Arc: {brief_data.get('narrative_arc', 'N/A')}\n"
            f"- Required Inclusions: {', '.join(brief_data.get('required_inclusions', ['N/A']))}\n"
            f"- Key Questions to Answer: {', '.join(brief_data.get('key_questions_to_answer', ['N/A']))}\n\n"
            "Write the full content of this chapter. Ensure it adheres to the brief."
        )
        
        print(f"✍️ {chapter.suggested_agent} generating content for chapter {chapter.chapter_number} - '{chapter.title}'...")

        # Execute the agent, expecting StringOutput as output
        run_result: RunResult = await Runner.run(agent_instance, agent_input)
        
        # Extract the string content
        content_output: StringOutput = run_result.final_output_as(StringOutput)
        content = content_output.text if content_output else None
        
        if content:
            await update_chapter_content(session, chapter_id=chapter.id, content=content)
            print(f"✅ Content generated successfully for chapter: {chapter_id}")
            
            # Log token usage
            # if run_result.usage:
            #     task_name = f"Chapter: Ch {chapter.chapter_number} - {chapter.title[:30]}..."
            #     await log_crew_run(
            #         session=session,
            #         project_id=project_id,
            #         initiating_task_name=task_name,
            #         usage_metrics=run_result.usage
            #     )
            # else:
            #     print(f"⚠️ No usage metrics available for Chapter Content Generation run for chapter {chapter_id}.")
            # return True
                        # NEW Check for usage data within raw_responses
            if hasattr(run_result, 'raw_responses') and run_result.raw_responses and hasattr(run_result.raw_responses[0], 'usage'):
                task_name = f"Chapter: Ch {chapter.chapter_number} - {chapter.title[:30]}..."
                await log_crew_run(
                    session=session,
                    project_id=project_id,
                    initiating_task_name=task_name,
                    usage_metrics=run_result # Pass the entire RunResult object
                )
            else:
                print(f"⚠️ No usage metrics available for Chapter Content Generation run for chapter {chapter_id}.")

            return True



        else:
            print(f"❌ Content generation failed for chapter: {chapter_id}. Agent returned no content.")
            chapter.status = "CONTENT_GEN_FAILED" # Update status
            await session.commit()
            return False

    except Exception as e:
        chapter_status_message = ""
        if chapter:
            chapter.status = "CONTENT_GEN_ERROR" # General error state
            try:
                await session.commit()
                chapter_status_message = f" for chapter {chapter.id}. Status set to {chapter.status}."
            except Exception as commit_e:
                print(f"❌ Failed to commit status update for chapter {chapter.id}: {commit_e}")
                chapter_status_message = f" for chapter {chapter.id} (status update failed)."
        
        print(f"🔥 Critical error during Chapter content generation{chapter_status_message}: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def run_transition_analysis_crew(session: AsyncSession, chapter_id: uuid.UUID) -> bool:
    print(f"🚀 Starting transition analysis for chapter: {chapter_id}")
    current_chapter = None # Initialize for error handling
    project_id = None # Initialize for logging
    try:
        current_chapter = await get_chapter_by_id(session, chapter_id=chapter_id)
        if not current_chapter or not current_chapter.part:
            print(f"❌ Transition analysis failed: Could not load chapter {chapter_id} or its part.")
            return False

        project_id = current_chapter.part.project_id # Get project_id for logging

        # Get all chapters in the part
        part_chapters_stmt = select(Chapter).where(
            Chapter.part_id == current_chapter.part_id
        ).order_by(Chapter.chapter_number)
        
        result = await session.execute(part_chapters_stmt)
        chapters_in_part = result.scalars().all()
        
        try:
            current_index = [c.id for c in chapters_in_part].index(current_chapter.id)
        except ValueError:
            print(f"❌ Transition analysis failed: Could not find chapter {chapter_id} in its part's list.")
            return False

        if current_index == 0:
            print(f"ℹ️ Chapter {chapter_id} is the first in its part. No transition analysis needed.")
            current_chapter.transition_feedback = "First chapter - no transition needed."
            current_chapter.status = "TRANSITION_DONE" # Indicate analysis completed/not needed
            await session.commit()
            return True

        preceding_chapter = chapters_in_part[current_index - 1]

        # CRITICAL FIX: Changed from silent return to raising an error
        if not current_chapter.content:
            error_msg = f"❌ Transition analysis failed: Current chapter {current_chapter.id} content is missing."
            print(error_msg)
            current_chapter.status = "CONTENT_MISSING_FOR_TRANSITION"
            await session.commit()
            raise ValueError(error_msg)
        
        if not preceding_chapter.content:
            error_msg = f"❌ Transition analysis failed: Preceding chapter {preceding_chapter.id} content is missing."
            print(error_msg)
            current_chapter.status = "CONTENT_MISSING_FOR_TRANSITION" # Apply to current chapter as it depends on preceding
            await session.commit()
            raise ValueError(error_msg)

        # Get the specific continuity editor agent instance
        agent_instance = continuity_editor_agent

        # Prepare a single string input, focusing on crucial parts of content
        agent_input = (
            f"Analyze the transition between two chapters and provide actionable feedback to improve narrative flow.\n\n"
            f"Previous Chapter Ending (last 500 chars):\n{preceding_chapter.content[-500:]}\n\n"
            f"Current Chapter Beginning (first 500 chars):\n{current_chapter.content[:500]}"
        )
        
        print(f"✂️ Continuity Editor AI analyzing transition for chapter {current_chapter.chapter_number}...")

        # Execute the agent, expecting StringOutput as output
        run_result: RunResult = await Runner.run(agent_instance, agent_input)
        
        # Extract the string content
        feedback_output: StringOutput = run_result.final_output_as(StringOutput)
        feedback = feedback_output.text if feedback_output else None

        if feedback:
            current_chapter.transition_feedback = feedback
            current_chapter.status = "TRANSITION_ANALYZED" # New status
            await session.commit()
            print(f"✅ Transition analysis complete for chapter: {chapter_id}. Feedback saved.")
            
            # Log token usage
            if run_result.usage:
                task_name = f"Transition: Ch {current_chapter.chapter_number}"
                await log_crew_run(
                    session=session,
                    project_id=project_id,
                    initiating_task_name=task_name,
                    usage_metrics=run_result.usage
                )
            else:
                print(f"⚠️ No usage metrics available for Transition Analysis run for chapter {chapter_id}.")
            return True
        else:
            print(f"❌ Transition analysis failed for chapter: {chapter_id}. Agent returned no feedback.")
            current_chapter.status = "TRANSITION_ANALYSIS_FAILED"
            await session.commit()
            return False

    except Exception as e:
        chapter_status_message = ""
        if current_chapter:
            current_chapter.status = "TRANSITION_ANALYSIS_ERROR" # General error state
            try:
                await session.commit()
                chapter_status_message = f" for chapter {current_chapter.id}. Status set to {current_chapter.status}."
            except Exception as commit_e:
                print(f"❌ Failed to commit status update for chapter {current_chapter.id}: {commit_e}")
                chapter_status_message = f" for chapter {current_chapter.id} (status update failed)."
        
        print(f"🔥 Critical error during Transition analysis{chapter_status_message}: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


async def run_finalization_crew(session: AsyncSession, project_id: uuid.UUID, task_type: str) -> bool:
    print(f"🚀 Starting Finalization Task ({task_type}) for project: {project_id}")
    project = None # Initialize for error handling
    try:
        project = await get_project_with_details(session, project_id=project_id)
        if not project:
            print(f"❌ Finalization failed: Project {project_id} not found.")
            return False

        # Build full book content
        full_book_content = ""
        has_content = False # Flag to check if any chapter content was found
        for part in sorted(project.parts, key=lambda p: p.part_number):
            full_book_content += f"\n\n--- PART {part.part_number}: {part.title} ---\n"
            full_book_content += f"Summary: {part.summary}\n"
            for chapter in sorted(part.chapters, key=lambda c: c.chapter_number):
                if chapter.content:
                    full_book_content += f"\n### CHAPTER {chapter.chapter_number}: {chapter.title} ###\n"
                    full_book_content += chapter.content
                    has_content = True

        if not has_content: # Check the flag
            print(f"❌ Finalization failed: No content found for project {project_id} to generate {task_type}.")
            project.status = "NO_CONTENT_FOR_FINALIZATION"
            await session.commit()
            return False

        # Get the theorist agent instance
        agent_instance = theorist_agent # Direct instance

        # Prepare input for theorist agent
        agent_input = (
            f"You are writing the {task_type} for a book.\n"
            f"The full content of the book is provided below. Synthesize it into a compelling {task_type}.\n\n"
            f"Book Content:\n{full_book_content}"
        )
        
        print(f"🎓 Theorist AI generating {task_type} for project {project_id}...")

        # Execute the agent, expecting StringOutput as output
        run_result: RunResult = await Runner.run(agent_instance, agent_input)
        
        # Extract the string content
        result_text_output: StringOutput = run_result.final_output_as(StringOutput)
        result_text = result_text_output.text if result_text_output else None

        if result_text:
            # Determine part_number and title for the final chapter (Introduction/Conclusion)
            if task_type.lower() == 'introduction':
                part_number = 0 # Conventionally, intro is part 0 or handled as a special chapter
                chapter_number = 1
                title = "Introduction"
            elif task_type.lower() == 'conclusion':
                # Find the maximum part number and add 1 for the conclusion's part
                part_number = max((p.part_number for p in project.parts), default=0) + 1
                chapter_number = 1
                title = "Conclusion"
            else:
                print(f"❌ Finalization failed: Invalid task_type '{task_type}'. Must be 'introduction' or 'conclusion'.")
                return False

            # Find or create a dedicated part for the finalization chapter
            final_part = next((p for p in project.parts if p.part_number == part_number), None)
            if not final_part:
                final_part = Part(
                    project_id=project.id,
                    part_number=part_number,
                    title=f"The Book's {title}", # Make it clear this is an auto-generated part
                    summary=f"This part contains the book's {task_type}."
                )
                session.add(final_part)
                await session.flush() # Flush to get final_part.id

            # Create final chapter
            new_chapter = Chapter(
                part_id=final_part.id,
                chapter_number=chapter_number,
                title=title,
                content=result_text,
                status="COMPLETE",
                suggested_agent="Theorist AI" # The agent that generated it
            )
            session.add(new_chapter)
            project.status = "COMPLETE" # Mark project as fully complete
            await session.commit()
            print(f"✅ {task_type} created successfully for project {project_id}. Project status: {project.status}.")

            # Log token usage
            if run_result.usage:
                await log_crew_run(
                    session=session,
                    project_id=project.id,
                    initiating_task_name=f"Phase 5: {task_type} Generation",
                    usage_metrics=run_result.usage
                )
            else:
                print(f"⚠️ No usage metrics available for {task_type} Generation run for project {project_id}.")
            return True
        else:
            print(f"❌ {task_type} generation failed for project: {project_id}. Agent returned no content.")
            project.status = f"{task_type.upper()}_GEN_FAILED"
            await session.commit()
            return False

    except Exception as e:
        project_status_message = ""
        if project:
            project.status = f"{task_type.upper()}_GEN_ERROR" # General error state
            try:
                await session.commit()
                project_status_message = f" for project {project.id}. Status set to {project.status}."
            except Exception as commit_e:
                print(f"❌ Failed to commit status update for project {project.id}: {commit_e}")
                project_status_message = f" for project {project.id} (status update failed)."
        
        print(f"🔥 Critical error during {task_type} generation{project_status_message}: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\tasks.py ---
# src/crew/tasks.py

from typing import Dict

from src.project.schemas import ChapterRead
from .schemas import PartListOutline, ChapterListOutline
from .agents import AGENT_ROSTER
# src/crew/tasks.py

def prepare_part_generation_inputs(raw_blueprint: str) -> dict:
    """Prepares inputs for the architect chain to generate book parts."""
    return {
        "raw_blueprint": raw_blueprint
    }

def prepare_chapter_detailing_inputs(part_title: str, part_summary: str) -> dict:
    """Prepares inputs for the architect chain to generate chapter details."""
    return {
        "part_title": part_title,
        "part_summary": part_summary
    }

def prepare_chapter_writing_inputs(chapter_data: dict) -> dict:
    """Prepares inputs for specialist chains to write chapter content."""
    brief = chapter_data.get("brief", {})
    return {
        "title": chapter_data.get("title", ""),
        "brief": (
            f"- Chapter Thesis: {brief.get('thesis_statement', '')}\n"
            f"- Narrative Arc: {brief.get('narrative_arc', '')}\n"
            f"- Key Questions: {', '.join(brief.get('key_questions_to_answer', []))}\n"
            f"- Required Inclusions: {', '.join(brief.get('required_inclusions', []))}"
        )
    }

def prepare_transition_analysis_inputs(preceding_end: str, current_start: str) -> dict:
    """Prepares inputs for continuity editor chain to analyze transitions."""
    return {
        "preceding_chapter_end": preceding_end[-500:],  # Last 500 chars
        "current_chapter_start": current_start[:500]    # First 500 chars
    }

def prepare_finalization_inputs(task_type: str, full_book_content: str) -> dict:
    """Prepares inputs for theorist chain to write introduction/conclusion."""
    return {
        "task_type": task_type,
        "full_book_content": full_book_content
    }

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\worker.py ---
# src/crew/worker.py
import uuid
from arq.connections import RedisSettings
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import AsyncSessionFactory
from src.core.config import settings
from .service import (
    run_part_generation_crew,
    run_chapter_detailing_crew,
    run_chapter_generation_crew,
    run_transition_analysis_crew,
    run_finalization_crew
)
from src.core.task_queue import task_queue

task_queue.configure(settings.REDIS_URL)

async def part_generation_worker(ctx, project_id: uuid.UUID) -> dict:
    """Worker for generating book parts"""
    async with AsyncSessionFactory() as session: # Correct way to manage session
        try:
            success = await run_part_generation_crew(session, project_id)
            return {
                "status": "success" if success else "failure",
                "project_id": str(project_id)
            }
        except Exception as e:
            print(f"❌ Part generation error for project {project_id}: {e}")
            return {
                "status": "error",
                "project_id": str(project_id),
                "error": str(e)
            }


async def chapter_detailing_worker(ctx, part_id: uuid.UUID) -> dict:
    """Worker for generating chapter details"""
    async with AsyncSessionFactory() as session: # Correct way to manage session
        try:
            await run_chapter_detailing_crew(session, part_id)
            return {"status": "success", "part_id": str(part_id)}
        except Exception as e:
            print(f"❌ Chapter detailing error for part {part_id}: {e}")
            return {
                "status": "error",
                "part_id": str(part_id),
                "error": str(e)
            }


async def chapter_generation_worker(ctx, chapter_id: uuid.UUID) -> dict:
    """Worker for generating chapter content"""
    async with AsyncSessionFactory() as session: # Correct way to manage session
        try:
            await run_chapter_generation_crew(session, chapter_id)
            return {"status": "success", "chapter_id": str(chapter_id)}
        except Exception as e:
            print(f"❌ Chapter generation error for {chapter_id}: {e}")
            return {
                "status": "error",
                "chapter_id": str(chapter_id),
                "error": str(e)
            }


async def transition_analysis_worker(ctx, chapter_id: uuid.UUID) -> dict:
    """Worker for analyzing chapter transitions"""
    async with AsyncSessionFactory() as session: # Correct way to manage session
        try:
            await run_transition_analysis_crew(session, chapter_id)
            return {"status": "success", "chapter_id": str(chapter_id)}
        except Exception as e:
            print(f"❌ Transition analysis error for chapter {chapter_id}: {e}")
            return {
                "status": "error",
                "chapter_id": str(chapter_id),
                "error": str(e)
            }


async def finalization_worker(ctx, project_id: uuid.UUID, task_type: str) -> dict:
    """Worker for writing introduction/conclusion"""
    async with AsyncSessionFactory() as session: # Correct way to manage session
        try:
            await run_finalization_crew(session, project_id, task_type)
            return {
                "status": "success",
                "project_id": str(project_id),
                "task": task_type
            }
        except Exception as e:
            print(f"❌ Finalization error ({task_type}) for project {project_id}: {e}")
            return {
                "status": "error",
                "project_id": str(project_id),
                "error": str(e)
            }

class WorkerSettings:
    """ARQ worker settings with all task handlers"""
    functions = [
        part_generation_worker,
        chapter_detailing_worker,
        chapter_generation_worker,
        transition_analysis_worker,
        finalization_worker
    ]
    redis_settings = task_queue.redis_settings

--- FILE: C:\Projects\57-scriptorium-engine\src\crew\__init__.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\project\chapter_router.py ---
# src/project/chapter_router.py
import uuid
from fastapi import APIRouter, Depends, status

from src.core.task_queue import task_queue
from src.project.schemas import ChapterRead
from src.crew.schemas import TaskStatus
from src.project.dependencies import valid_chapter_id

# NEW: Import RateLimiter
from fastapi_limiter.depends import RateLimiter

router = APIRouter(prefix="/chapters", tags=["Chapters"])

@router.post(
    "/{chapter_id}/generate",
    status_code=status.HTTP_202_ACCEPTED,
    response_model=TaskStatus,
    summary="Queue Chapter Content Generation",
    dependencies=[Depends(RateLimiter(times=20, seconds=60))] # NEW: 20 requests per minute (can be many chapters)
)
async def queue_chapter_generation(
    chapter: ChapterRead = Depends(valid_chapter_id),
):
    """
    Queues a background job to write the content for a specific chapter
    using the dynamically selected AI agent.
    """
    job = await task_queue.enqueue("chapter_generation_worker", chapter.id)
    return TaskStatus(job_id=job.job_id, status="queued")


# --- NEW ENDPOINT ---
@router.post(
    "/{chapter_id}/analyze-transition",
    status_code=status.HTTP_202_ACCEPTED,
    response_model=TaskStatus,
    summary="Queue Transition Analysis",
    dependencies=[Depends(RateLimiter(times=30, seconds=60))] # NEW: Higher rate for analysis
)
async def queue_transition_analysis(
    chapter: ChapterRead = Depends(valid_chapter_id),
):
    """
    Queues a background job for the Continuity Editor AI to analyze the
    narrative flow between this chapter and the one preceding it.
    The feedback is saved directly to the chapter in the database.
    """
    job = await task_queue.enqueue("transition_analysis_worker", chapter.id)
    return TaskStatus(job_id=job.job_id, status="queued")

--- FILE: C:\Projects\57-scriptorium-engine\src\project\dependencies.py ---
# src/project/dependencies.py
import uuid
from fastapi import Depends, HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import get_db_session
from . import service

# UPDATED: Import PartRead schema
from .schemas import ProjectRead, ChapterRead, PartRead

async def valid_project_id(
    project_id: uuid.UUID,
    session: AsyncSession = Depends(get_db_session)
) -> ProjectRead:
    """
    Dependency that validates a project exists and returns it.
    Raises a 404 HTTPException if the project is not found.
    """
    project = await service.get_project_by_id(session=session, project_id=project_id)
    if not project:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Project with ID {project_id} not found."
        )
    return project

# NEW: Dependency for validating a part_id
async def valid_part_id(
    part_id: uuid.UUID,
    session: AsyncSession = Depends(get_db_session)
) -> PartRead:
    """
    Dependency that validates a part exists and returns it.
    Raises a 404 HTTPException if the part is not found.
    """
    # We use the get_part_by_id service function we created earlier
    part = await service.get_part_by_id(session=session, part_id=part_id)
    if not part:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Part with ID {part_id} not found."
        )
    return part


async def valid_chapter_id(
    chapter_id: uuid.UUID,
    session: AsyncSession = Depends(get_db_session)
) -> ChapterRead:
    """
    Dependency that validates a chapter exists and returns it.
    Raises a 404 HTTPException if the chapter is not found.
    """
    chapter = await service.get_chapter_by_id(session=session, chapter_id=chapter_id)
    if not chapter:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Chapter with ID {chapter_id} not found."
        )
    return chapter

--- FILE: C:\Projects\57-scriptorium-engine\src\project\exceptions.py ---


--- FILE: C:\Projects\57-scriptorium-engine\src\project\models.py ---
# src/project/models.py
import uuid
from sqlalchemy import Column, String, TEXT, Integer, ForeignKey, Numeric
from sqlalchemy.orm import relationship
from sqlalchemy.types import JSON
from sqlalchemy.dialects.postgresql import UUID
from src.core.database import Base

class Project(Base):
    __tablename__ = "projects"
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    raw_blueprint = Column(TEXT, nullable=False)
    structured_outline = Column(JSON, nullable=True)
    status = Column(String, default="RAW_IDEA", nullable=False)
    summary_outline = Column(TEXT, nullable=True)
    total_cost = Column(Numeric(10, 8), nullable=False, default=0.0)
    parts = relationship("Part", back_populates="project", cascade="all, delete-orphan")

class Part(Base):
    __tablename__ = "parts"
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    project_id = Column(UUID(as_uuid=True), ForeignKey("projects.id"), nullable=False)
    part_number = Column(Integer, nullable=False)
    title = Column(String, nullable=False)
    summary = Column(TEXT, nullable=True)

    # NEW: To track the status of chapter generation for this part.
    status = Column(String, default="DEFINED", nullable=False)

    project = relationship("Project", back_populates="parts")
    chapters = relationship("Chapter", back_populates="part", cascade="all, delete-orphan", order_by="Chapter.chapter_number")

class Chapter(Base):
    __tablename__ = "chapters"
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    part_id = Column(UUID(as_uuid=True), ForeignKey("parts.id"), nullable=False)
    chapter_number = Column(Integer, nullable=False)
    title = Column(String, nullable=False)
    brief = Column(JSON, nullable=True)
    content = Column(TEXT, nullable=True)
    status = Column(String, default="BRIEF_PENDING_VALIDATION")
    suggested_agent = Column(String, nullable=True)
    transition_feedback = Column(TEXT, nullable=True)
    part = relationship("Part", back_populates="chapters")

--- FILE: C:\Projects\57-scriptorium-engine\src\project\part_router.py ---
# src/project/part_router.py
import uuid
from fastapi import APIRouter, Depends, status, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import get_db_session
from . import service

# Import the necessary schemas and dependencies
from .schemas import PartReadWithChapters
from src.crew.schemas import ChapterListOutline
from .dependencies import valid_part_id

router = APIRouter(
    prefix="/parts",
    tags=["Parts"]
)

# NEW: Endpoint for Phase 2 Validation
@router.put(
    "/{part_id}/finalize-chapters",
    response_model=PartReadWithChapters,
    summary="Finalize the Chapter structure for a Part"
)
async def finalize_part_chapters(
    part_id: uuid.UUID,
    validated_chapters: ChapterListOutline, # The user submits the approved structure
    session: AsyncSession = Depends(get_db_session)
):
    """
    Takes a validated list of Chapters for a specific Part and creates the
    official Chapter records in the database.
    """
    updated_part = await service.finalize_chapter_structure(
        session=session,
        part_id=part_id,
        validated_chapters=validated_chapters
    )
    if not updated_part:
        raise HTTPException(status_code=404, detail="Part not found")
    return updated_part

--- FILE: C:\Projects\57-scriptorium-engine\src\project\router.py ---
# src/project/router.py
import uuid
from fastapi import APIRouter, Depends, status, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import get_db_session
from . import service

# UPDATED: Import the schemas needed for the new endpoint
from .schemas import ProjectCreate, ProjectRead, ProjectDetailRead
from src.crew.schemas import PartListOutline # This schema is for the request body

from .dependencies import valid_project_id

router = APIRouter(
    prefix="/projects",
    tags=["Projects"]
)

@router.post(
    "/",
    response_model=ProjectRead,
    status_code=status.HTTP_201_CREATED,
    summary="Create a new book project"
)
async def create_new_project(
    project_data: ProjectCreate,
    session: AsyncSession = Depends(get_db_session)
):
    """Creates a new project record from a user's 'raw_blueprint'."""
    new_project = await service.create_project(session=session, project_data=project_data)
    return new_project

@router.get(
    "/{project_id}",
    response_model=ProjectDetailRead,
    summary="Get Full Project Details"
)
async def get_project_details(
    project_id: uuid.UUID,
    session: AsyncSession = Depends(get_db_session)
):
    """
    Retrieves the full details of a project, including all its
    parts and chapters, for display on a dashboard.
    """
    project = await service.get_project_with_details(session=session, project_id=project_id)
    if not project:
        raise HTTPException(status_code=404, detail="Project not found")
    return project

# NEW: Endpoint for Phase 1 Validation
@router.put(
    "/{project_id}/finalize-parts",
    response_model=ProjectDetailRead,
    summary="Finalize the Part structure of a book"
)
async def finalize_project_parts(
    project_id: uuid.UUID,
    validated_parts: PartListOutline, # The user submits the approved structure
    session: AsyncSession = Depends(get_db_session)
):
    """
    Takes a validated list of Parts from the user and creates the official
    Part records in the database, finalizing the book's high-level structure.
    """
    updated_project = await service.finalize_part_structure(
        session=session,
        project_id=project_id,
        validated_parts=validated_parts
    )
    if not updated_project:
        raise HTTPException(status_code=404, detail="Project not found")
    return updated_project


--- FILE: C:\Projects\57-scriptorium-engine\src\project\schemas.py ---
# src/project/schemas.py
import uuid
from decimal import Decimal
from pydantic import BaseModel, Field
from typing import List, Dict, Any
from src.crew.schemas import ChapterBrief
from pydantic import field_validator

# --- Main Application Schemas ---

class ProjectCreate(BaseModel):
    """The schema for creating a project from a raw text blueprint."""
    # UPDATED: Renamed to match the new database model.
    raw_blueprint: str

# --- Read Schemas (for API responses) ---

class ProjectRead(BaseModel):
    """Base read schema for a project."""
    id: uuid.UUID
    
    # UPDATED: Renamed to match the model.
    raw_blueprint: str
    
    # NEW: To show the project's current phase.
    status: str
    
    # NEW: To show the evolving structured data.
    structured_outline: Dict[str, Any] | None = None
    
    total_cost: Decimal

    @field_validator('structured_outline')
    def validate_outline(cls, value):
        if value is not None and not isinstance(value, dict):
            raise ValueError("structured_outline must be a dictionary")
        return value

    class Config:
        from_attributes = True

class PartRead(BaseModel):
    """Read schema for a single Part."""
    id: uuid.UUID
    part_number: int
    title: str
    summary: str | None = None

    class Config:
        from_attributes = True

class ChapterRead(BaseModel):
    """Read schema for a single Chapter, using the 'brief' field."""
    id: uuid.UUID
    chapter_number: int
    title: str
    brief: ChapterBrief | None = None
    status: str
    suggested_agent: str | None = None
    part: PartRead

    class Config:
        from_attributes = True

class PartReadWithChapters(PartRead):
    """Read schema for a Part that includes its nested Chapters."""
    chapters: list[ChapterRead] = []

class ProjectDetailRead(ProjectRead):
    """Read schema for a full Project, including all its Parts and Chapters."""
    parts: list[PartReadWithChapters] = []

--- FILE: C:\Projects\57-scriptorium-engine\src\project\service.py ---
# src/project/service.py
import uuid
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload, subqueryload
from sqlalchemy import delete
from sqlalchemy.orm import selectinload, subqueryload # Ensure this is present
from sqlalchemy import delete, select # Ensure delete and select are present
from .models import Project, Part, Chapter
from .schemas import ProjectCreate
from src.crew.schemas import PartListOutline, ChapterListOutline
async def create_project(session: AsyncSession, project_data: ProjectCreate) -> Project:
    """Creates a new project record from a user's raw text blueprint."""
    new_project = Project(**project_data.model_dump())
    session.add(new_project)
    await session.commit()
    await session.refresh(new_project)
    return new_project

async def get_project_by_id(session: AsyncSession, project_id: uuid.UUID) -> Project | None:
    """Retrieves a single project by its ID."""
    result = await session.execute(select(Project).where(Project.id == project_id))
    return result.scalars().first()

async def get_project_with_details(session: AsyncSession, project_id: uuid.UUID) -> Project | None:
    """Retrieves a project and eagerly loads its parts and their chapters."""
    result = await session.execute(
        select(Project).options(
            subqueryload(Project.parts).subqueryload(Part.chapters)
        ).where(Project.id == project_id)
    )
    return result.scalars().first()

async def get_part_by_id(session: AsyncSession, part_id: uuid.UUID) -> Part | None:
    """Retrieves a single part by its ID, including its parent project."""
    result = await session.execute(
        select(Part).options(selectinload(Part.project)).where(Part.id == part_id)
    )
    return result.scalars().first()

async def get_chapter_by_id(session: AsyncSession, chapter_id: uuid.UUID) -> Chapter | None:
    """Retrieves a single chapter by its ID, and pre-loads its parent part and project."""
    result = await session.execute(
        select(Chapter).options(
            selectinload(Chapter.part).selectinload(Part.project)
        ).where(Chapter.id == chapter_id)
    )
    return result.scalars().first()

async def finalize_part_structure(
    session: AsyncSession, project_id: uuid.UUID, validated_parts: PartListOutline
) -> Project:
    """
    Deletes existing parts for a project and creates new ones based on the
    user-validated structure. Updates the project status.
    """
    project = await get_project_with_details(session, project_id)
    if not project:
        return None

    project.parts.clear()
    await session.flush()

    for part_data in validated_parts.parts:
        new_part = Part(
            project_id=project.id,
            part_number=part_data.part_number,
            title=part_data.title,
            summary=part_data.summary
        )
        project.parts.append(new_part)

    project.status = "PARTS_VALIDATED"
    session.add(project)
    await session.commit()
    await session.refresh(project)

    return project

async def finalize_chapter_structure(
    session: AsyncSession, part_id: uuid.UUID, validated_chapters: ChapterListOutline
) -> Part:
    """
    Deletes existing chapters for a part and creates new ones based on the
    user-validated structure. Updates the part's status.
    """
    part = await get_part_by_id(session, part_id)
    if not part:
        return None

    # Delete existing chapters directly via a query
    await session.execute(
        delete(Chapter).where(Chapter.part_id == part.id)
    )
    # No need for flush here. The commit below will handle the delete before the add.
    # If you were doing more complex operations between delete and add, flush would be good.


    for chapter_data in validated_chapters.chapters:
        new_chapter = Chapter(
            part_id=part.id,
            chapter_number=chapter_data.chapter_number,
            title=chapter_data.title,
            brief=chapter_data.brief.model_dump(),
            suggested_agent=chapter_data.suggested_agent,
            status="BRIEF_COMPLETE"
        )
        session.add(new_chapter)

    part.status = "CHAPTERS_VALIDATED"
    # session.add(part) # No need to add part if it's already a managed object

    await session.commit()

    # NEW: Re-fetch the part, eagerly loading its chapters for the response model
    # This ensures the chapters are loaded within the async session context
    # before the session is yielded/closed by the dependency.
    refreshed_part_stmt = select(Part).options(
        selectinload(Part.chapters)
    ).where(Part.id == part_id)
    
    result = await session.execute(refreshed_part_stmt)
    refreshed_part = result.scalars().first()

    return refreshed_part # Return the eagerly loaded part

async def update_chapter_content(session: AsyncSession, chapter_id: uuid.UUID, content: str) -> Chapter | None:
    """Updates the content of a specific chapter and sets its status to 'Complete'."""
    chapter = await get_chapter_by_id(session, chapter_id)
    if chapter:
        chapter.content = content
        chapter.status = "Complete"
        await session.commit()
        await session.refresh(chapter)
    return chapter

async def update_project_summary_outline(session: AsyncSession, project_id: uuid.UUID, outline: str) -> Project | None:
    """(Legacy) Updates the summary_outline field of a project."""
    project = await get_project_by_id(session, project_id)
    if project:
        project.summary_outline = outline
        await session.commit()
        await session.refresh(project)
    return project

--- FILE: C:\Projects\57-scriptorium-engine\src\project\__init__.py ---
